{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c3debfd",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0912044e",
   "metadata": {},
   "source": [
    "Chapter 17 of `cite`{zaki2020data}: [Clustering Validation](https://www.cs.rpi.edu/~zaki/DMML/slides/pdf/ychap17.pdf)\n",
    "\n",
    "# Clustering Validation Metrics\n",
    "\n",
    "## Introduction to Clustering Validation\n",
    "\n",
    "Clustering validation helps assess the quality of clustering results. There are three main types of validation measures:\n",
    "\n",
    "1. **External measures**: Use external information like ground truth labels\n",
    "2. **Internal measures**: Use only the data and clustering results\n",
    "3. **Relative measures**: Compare different clusterings\n",
    "\n",
    "We'll focus on several popular external and internal measures.\n",
    "\n",
    "## External Validation Measures\n",
    "\n",
    "### Contingency Table Basics\n",
    "\n",
    "First, let's define some key quantities used in external measures:\n",
    "\n",
    "- **TP (True Positives)**: Pairs in same cluster and same true partition\n",
    "- **FP (False Positives)**: Pairs in same cluster but different partitions\n",
    "- **TN (True Negatives)**: Pairs in different clusters and different partitions\n",
    "- **FN (False Negatives)**: Pairs in different clusters but same partition\n",
    "\n",
    "These can be computed from the contingency table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b9ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_contingency_table(cluster_labels, true_labels):\n",
    "    \"\"\"Compute contingency table: n_ij = number of items in cluster i and class j\"\"\"\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    unique_classes = np.unique(true_labels)\n",
    "    n_ij = np.zeros((len(unique_clusters), len(unique_classes)))\n",
    "    \n",
    "    for cluster_idx, cluster in enumerate(unique_clusters):\n",
    "        for class_idx, class_ in enumerate(unique_classes):\n",
    "            n_ij[cluster_idx, class_idx] = np.sum((cluster_labels == cluster) & (true_labels == class_))\n",
    "    \n",
    "    return n_ij"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166e44d1",
   "metadata": {},
   "source": [
    "All of the external measures rely on the $r \\times k$  **contingency table** $\\mathbf{N}$ that is induced by a clustering $\\mathbf{C}$ and the ground-truth partitioning $\\mathbf{T}$, defined as follows:  \n",
    "\n",
    "$$\n",
    "\\mathbf{N}(i,j) = n_{ij}  = \\left| C_i \\cap T_{j} \\right|\n",
    "$$\n",
    "\n",
    "The count $n_{ij}$ denotes the number of points that are common to cluster $C_i$ and ground-truth partition $T_{j}$.  \n",
    "\n",
    "Let $n_{i} = |C_i|$ denote the number of points in cluster $C_i$, and let $m_{j} = |T_{j}|$ denote the number of points in partition  \n",
    "$T_{j}$.  \n",
    "The contingency table can be computed from $\\mathbf{T}$ and $\\mathbf{C}$ in $O(n)$ time by examining the partition and cluster labels, $y_i$ and  $\\hat{y}_i$, for each point $\\mathbf{x}_i \\in \\mathbf{D}$ and incrementing the corresponding count $n_{y_i\\hat{y}_i}$.  \n",
    "\n",
    "Let $G$ be a bipartite graph over the vertex set $V = \\mathbf{C} \\cup \\mathbf{T}$, and let the edge set be $E = \\{ (C_i, T_{j}) \\}$ with  \n",
    "edge weights $w(C_i,T_{j}) = n_{ij}$.  \n",
    "A **matching** $M$ in $G$ is a subset of $E$, such that the edges in $M$ are pairwise nonadjacent, meaning they do not have a common vertex.  \n",
    "\n",
    "### **Maximum Weight Matching**  \n",
    "The maximum weight matching in $G$ is given as:\n",
    "\n",
    "$$\n",
    "\\mathit{match} = \\arg \\max_M \\left\\{ \\frac{w(M)}{n} \\right\\}\n",
    "$$\n",
    "\n",
    "where $w(M)$ is the sum of all edge weights in matching $M$,  given as $w(M) = \\sum_{e \\in M} w(e)$.  \n",
    "\n",
    "### **Precision**  \n",
    "Given cluster $C_i$, let $j_i$ denote the partition that contains the maximum number of points from $C_i$,\n",
    "that is, $j_i = \\max_{j=1}^k \\{ n_{ij} \\}$. \n",
    "The precision of a cluster $C_i$ is the same as its purity:\n",
    "\n",
    "$$\n",
    "\\mathit{prec}_i = \\frac{1}{n_{i}}\\max_{j=1}^k \\left\\{ n_{ij} \\right\\} =\n",
    "\\frac{n_{ij_i}}{n_i}\n",
    "$$\n",
    "\n",
    "### **Recall**  \n",
    "The recall of cluster $C_i$ is defined as:\n",
    "\n",
    "$$\n",
    "\\mathit{recall}_i = \\frac{n_{ij_i}}{|\\mathbf{T}_{j_i}|} =\\frac{n_{ij_i}}{m_{j_i}}\n",
    "$$\n",
    "\n",
    "where $m_{j_i} = |\\mathbf{T}_{j_i}|$.  \n",
    "\n",
    "### **F-Measure**  \n",
    "The F-measure is the harmonic mean of the precision and recall values for  \n",
    "each $C_i$:\n",
    "\n",
    "$$\n",
    "F_i = \\frac{2}{\\frac{1}{\\mathit{prec}_i} + \\frac{1}{\\mathit{recall}_i}} =\n",
    "\\frac{2 \\cdot \\mathit{prec}_i \\cdot \\mathit{recall}_i}{\\mathit{prec}_i + \\mathit{recall}_i} =\n",
    "\\frac{2 \\; n_{ij_i}}{n_{i} + m_{j_i}}\n",
    "$$\n",
    "\n",
    "The **F-measure** for the clustering $\\mathbf{C}$ is the mean of clusterwise  \n",
    "F-measure values:\n",
    "\n",
    "$$\n",
    "F = \\frac{1}{r} \\sum_{i=1}^r F_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd8b35",
   "metadata": {},
   "source": [
    "### 1. Purity\n",
    "\n",
    "Purity measures how \"pure\" each cluster is by the fraction of points from the majority class:\n",
    "\n",
    "$$\n",
    "\\text{purity} = \\frac{1}{n}\\sum_{i=1}^r \\max_{j=1}^k \\{n_{ij}\\}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ n $ = total number of points\n",
    "- $ r $ = number of clusters\n",
    "- $ k $ = number of true classes\n",
    "- $ n_{ij} $ = number of points in cluster $ i $ from class $ j $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc26fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score(cluster_labels, true_labels):\n",
    "    contingency_matrix = compute_contingency_table(cluster_labels, true_labels)\n",
    "    return np.sum(np.amax(contingency_matrix, axis=1)) / np.sum(contingency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93210172",
   "metadata": {},
   "source": [
    "### 2. Maximum Matching\n",
    "\n",
    "Finds the best matching between clusters and true classes to maximize overlap:\n",
    "\n",
    "$$\n",
    "\\text{match} = \\frac{1}{n}\\max_M \\sum_{(i,j)\\in M} n_{ij}\n",
    "$$\n",
    "\n",
    "Where $ M $ is a matching between clusters and classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d165bf3e",
   "metadata": {},
   "source": [
    "### Maximum Matching Example (Bipartite Graph Interpretation)\n",
    "\n",
    "**Scenario**: Imagine we have clustered 10 fruits into 3 clusters, and we know their true categories (ground truth):\n",
    "\n",
    "```\n",
    "Cluster Assignments (C₁, C₂, C₃):\n",
    "C₁: [apple1, apple2, banana1]\n",
    "C₂: [orange1, orange2, apple3] \n",
    "C₃: [banana2, banana3, orange3, apple4]\n",
    "\n",
    "True Categories (T₁=apples, T₂=oranges, T₃=bananas):\n",
    "T₁: apple1, apple2, apple3, apple4\n",
    "T₂: orange1, orange2, orange3\n",
    "T₃: banana1, banana2, banana3\n",
    "```\n",
    "\n",
    "**Step 1: Build the Bipartite Graph**\n",
    "\n",
    "We create edges between clusters and categories with weights equal to their overlap:\n",
    "\n",
    "```\n",
    "Clusters       Categories\n",
    "   C₁ ------------- T₁ (weight=2: apple1,apple2)\n",
    "      \\------------ T₃ (weight=1: banana1)\n",
    "   C₂ ------------- T₁ (weight=1: apple3)\n",
    "      \\------------ T₂ (weight=2: orange1,orange2)\n",
    "   C₃ ------------- T₂ (weight=1: orange3)\n",
    "      \\------------ T₃ (weight=2: banana2,banana3)\n",
    "      \\------------ T₁ (weight=1: apple4)\n",
    "```\n",
    "\n",
    "**Step 2: Find Maximum Weight Matching**\n",
    "\n",
    "We want to match each cluster to at most one category (and vice versa) to maximize total weight:\n",
    "\n",
    "Possible matching options:\n",
    "1. Match C₁-T₁ (2), C₂-T₂ (2), C₃-T₃ (2) → Total weight = 6\n",
    "2. Match C₁-T₃ (1), C₂-T₂ (2), C₃-T₁ (1) → Total weight = 4\n",
    "\n",
    "The first option gives us the maximum weight matching.\n",
    "\n",
    "**Step 3: Calculate Maximum Matching Score**\n",
    "\n",
    "$$\n",
    "\\text{match} = \\frac{\\text{Total matched weight}}{n} = \\frac{2+2+2}{10} = 0.6\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d50098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal matching: [(0, 0), (1, 1), (2, 2)]\n",
      "Max weight: 6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Define contingency table\n",
    "contingency = np.array([\n",
    "    [2, 0, 1],  # C₁: 2 apples, 0 oranges, 1 banana\n",
    "    [1, 2, 0],  # C₂: 1 apple, 2 oranges, 0 bananas\n",
    "    [1, 1, 2]   # C₃: 1 apple, 1 orange, 2 bananas\n",
    "])\n",
    "\n",
    "# Find optimal matching\n",
    "row_ind, col_ind = linear_sum_assignment(contingency, maximize=True)\n",
    "\n",
    "# Perform indexing correctly\n",
    "max_weight = contingency[row_ind, col_ind].sum()\n",
    "\n",
    "print(f\"Optimal matching: {list(zip(row_ind, col_ind))}\")\n",
    "print(f\"Max weight: {max_weight}\")\n",
    "\n",
    "# Optimal matching: [(0, 0), (1, 1), (2, 2)]  # C₁-T₁, C₂-T₂, C₃-T₃"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e993ca",
   "metadata": {},
   "source": [
    "**Key Insights**:\n",
    "1. This ensures one cluster maps to only one true category\n",
    "2. Unlike purity, we don't double-count categories\n",
    "3. The score ranges from 0 (worst) to 1 (perfect matching)\n",
    "4. In our fruit example, 0.6 indicates moderate alignment between clusters and true categories\n",
    "\n",
    "**Real-world analogy**: Imagine this as assigning each project team (cluster) to exactly one department (category) where you want to maximize the number of correctly assigned team members."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6e40fb",
   "metadata": {},
   "source": [
    "### 3. Precision, Recall and F-measure\n",
    "\n",
    "For each cluster $ C_i $:\n",
    "\n",
    "- **Precision**: Fraction of points in cluster from majority class\n",
    "$$\n",
    "\\text{prec}_i = \\frac{n_{ij_i}}{n_i}\n",
    "$$\n",
    "\n",
    "- **Recall**: Fraction of points from class found in cluster\n",
    "$$\n",
    "\\text{recall}_i = \\frac{n_{ij_i}}{m_{j_i}}\n",
    "$$\n",
    "\n",
    "- **F-measure**: Harmonic mean of precision and recall\n",
    "$$\n",
    "F_i = \\frac{2 \\cdot \\text{prec}_i \\cdot \\text{recall}_i}{\\text{prec}_i + \\text{recall}_i} = \\frac{2n_{ij_i}}{n_i + m_{j_i}}\n",
    "$$\n",
    "\n",
    "Overall F-measure is the average of cluster F-measures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b75bff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26cc412a",
   "metadata": {},
   "source": [
    "# Clustering Validation Metrics Tutorial\n",
    "\n",
    "### Example 17.1: Good vs Bad Clustering on Iris Data\n",
    "\n",
    "Let's examine two different clusterings of the Iris dataset using principal components:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9925ebcf",
   "metadata": {},
   "source": [
    "#### Good Clustering Results:\n",
    "\n",
    "![](img/Zaki-Chap17-Good-Clustering.png)\n",
    "\n",
    "### Contingency Table\n",
    "\n",
    "|   | iris-setosa | iris-versicolor | iris-virginica | Total (n_i) |\n",
    "|---|------------|----------------|---------------|-------------|\n",
    "| C₁ (squares)  | 0  | 47  | 14  | 61  |\n",
    "| C₂ (circles)  | 50 | 0   | 0   | 50  |\n",
    "| C₃ (triangles) | 0  | 3   | 36  | 39  |\n",
    "| **Total (m_j)** | 50 | 50  | 50  | **n = 100** |\n",
    "\n",
    "**Purity:** 0.887  \n",
    "**Match:** 0.887  \n",
    "**F:** 0.885  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dcdd11",
   "metadata": {},
   "source": [
    "#### Bad Clustering Results:\n",
    "\n",
    "![](img/Zaki-Chap17-Bad-Clustering.png)\n",
    "\n",
    "### Contingency Table\n",
    "\n",
    "|   | iris-setosa | iris-versicolor | iris-virginica | Total (n_i) |\n",
    "|---|------------|----------------|---------------|-------------|\n",
    "| C₁ (squares)  | 30  | 0   | 0   | 30  |\n",
    "| C₂ (circles)  | 20  | 4   | 0   | 24  |\n",
    "| C₃ (triangles) | 0  | 46  | 50  | 96  |\n",
    "| **Total (m_j)** | 50  | 50  | 50  | **n = 150** |\n",
    "\n",
    "**Purity:** 0.667  \n",
    "**Match:** 0.560  \n",
    "**F:** 0.658  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889998ed",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Pairwise Measures\n",
    "\n",
    "#### Jaccard Coefficient\n",
    "$$\n",
    "\\text{Jaccard} = \\frac{TP}{TP + FN + FP}\n",
    "$$\n",
    "\n",
    "#### Rand Index\n",
    "$$\n",
    "\\text{Rand} = \\frac{TP + TN}{TP + FN + FP + TN} = \\frac{TP + TN}{\\binom{n}{2}}\n",
    "$$\n",
    "\n",
    "## Internal Validation Measures\n",
    "\n",
    "### Silhouette Coefficient\n",
    "\n",
    "Measures how similar a point is to its own cluster compared to other clusters:\n",
    "\n",
    "For each point $ x_i $:\n",
    "$$\n",
    "s_i = \\frac{b_i - a_i}{\\max(a_i, b_i)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ a_i $ = average distance to other points in same cluster\n",
    "- $ b_i $ = min average distance to points in another cluster\n",
    "\n",
    "Overall score is average of all $ s_i $.\n",
    "\n",
    "## Python Example on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0899540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.887\n",
      "Rand Index: 0.716\n",
      "Silhouette Score: 0.551\n",
      "Jaccard: 0.682\n",
      "Rand Index: 0.874\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (pairwise_distances, \n",
    "                            adjusted_rand_score,\n",
    "                            silhouette_score)\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Cluster with K-means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "# External measures\n",
    "contingency = compute_contingency_table(cluster_labels, y)\n",
    "print(f\"Purity: {purity_score(cluster_labels, y):.3f}\")\n",
    "print(f\"Rand Index: {adjusted_rand_score(y, cluster_labels):.3f}\")\n",
    "\n",
    "# Internal measure\n",
    "print(f\"Silhouette Score: {silhouette_score(X, cluster_labels):.3f}\")\n",
    "\n",
    "# Pairwise measures\n",
    "def pairwise_metrics(y_true, y_pred):\n",
    "    tp = fp = fn = tn = 0\n",
    "    n = len(y_true)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            same_cluster = y_pred[i] == y_pred[j]\n",
    "            same_class = y_true[i] == y_true[j]\n",
    "            \n",
    "            if same_cluster and same_class:\n",
    "                tp += 1\n",
    "            elif same_cluster and not same_class:\n",
    "                fp += 1\n",
    "            elif not same_cluster and same_class:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "                \n",
    "    jaccard = tp / (tp + fn + fp)\n",
    "    rand = (tp + tn) / (tp + fp + fn + tn)\n",
    "    \n",
    "    return jaccard, rand\n",
    "\n",
    "jaccard, rand = pairwise_metrics(y, cluster_labels)\n",
    "print(f\"Jaccard: {jaccard:.3f}\")\n",
    "print(f\"Rand Index: {rand:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6753765c",
   "metadata": {},
   "source": [
    "\n",
    "## Interpretation of Results\n",
    "\n",
    "- **Purity**: Higher is better (max 1.0)\n",
    "- **Rand Index**: Higher is better (max 1.0)\n",
    "- **Silhouette**: Ranges from -1 to 1, higher is better\n",
    "- **Jaccard**: Higher is better (max 1.0)\n",
    "\n",
    "## Choosing the Right Metric\n",
    "\n",
    "1. Use external measures when ground truth is available\n",
    "2. Use internal measures when no labels exist\n",
    "3. Consider multiple metrics together for robust evaluation\n",
    "\n",
    "Remember that no single metric tells the whole story - different metrics may be more appropriate for different clustering goals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4466c02d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c94367e1",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "Here are several real-world examples of bipartite matching problems that help explain the concept of maximum matching in clustering validation, along with relevant links for further reading:\n",
    "\n",
    "### 1. **Stable Marriage Problem**\n",
    "**Scenario**: Matching medical students to hospital residency programs based on mutual preferences    \n",
    "**Visualization**:\n",
    "```\n",
    "Students   Hospitals\n",
    "  A ──────── X (1st choice)\n",
    "  B ──┬───── Y \n",
    "     └───── Z (tie)\n",
    "  C ──────── Y (only option)\n",
    "```\n",
    "**Key Insight**: The Gale-Shapley algorithm finds stable pairings where no unmatched pair prefers each other over their current matches  \n",
    "**Resource**: [Wikipedia - Stable Marriage Problem](https://en.wikipedia.org/wiki/Stable_marriage_problem)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Roommate Assignment**\n",
    "**Scenario**: Matching college students as roommates based on compatibility scores    \n",
    "**Example Matrix**:\n",
    "```\n",
    "       Clean | Social | Studious\n",
    "Alice    5   |   3    |    2\n",
    "Bob      2   |   4    |    1\n",
    "Carol    4   |   1    |    5\n",
    "```\n",
    "**Optimal Matching**: Alice-Clean (5), Bob-Social (4), Carol-Studious (5) → Total=14  \n",
    "**Resource**: [Roommate Assignment Algorithms](https://en.wikipedia.org/wiki/Stable_roommates_problem)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Thesis Advisor Matching**\n",
    "**Scenario**: Assigning graduate students to faculty advisors based on research interests  \n",
    "**Connection**: Similar to ensuring each cluster (advisor group) best represents one true category (research area)  \n",
    "**Process Flow**:\n",
    "1. Students rank advisors\n",
    "2. Advisors rank students\n",
    "3. Solve using maximum weight matching  \n",
    "**Visualization**:\n",
    "```\n",
    "Students     Research Areas\n",
    "  Sara ────┐\n",
    "           ├── ML (Prof. Smith)\n",
    "  John ────┘\n",
    "  Emma ────── NLP (Prof. Lee)\n",
    "```\n",
    "**Resource**: \n",
    "- [Match Day 101: How does the medical residency match work?](https://scopeblog.stanford.edu/2024/03/13/match-day-medical-school-residency/)\n",
    "- [Dr. Amin Saberi](https://stanford.edu/~saberi)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Image Feature Matching**\n",
    "**Scenario**: Matching keypoints between two images of the same object  \n",
    "**Example**:\n",
    "```\n",
    "Image A Features   Image B Features\n",
    "   Corner X ─────────── Edge P (distance=1.2)\n",
    "   Blob Y ──┬────────── Corner Q (distance=0.8)\n",
    "           └────────── Blob R (distance=1.5)\n",
    "```\n",
    "**Optimal Matching**: X-P (1.2), Y-Q (0.8) → Total=2.0  \n",
    "**Algorithm**: Hungarian algorithm on distance matrix  \n",
    "**Resource**: [OpenCV Feature Matching](https://docs.opencv.org/4.x/dc/dc3/tutorial_py_matcher.html)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Job Applicant Matching**\n",
    "**Scenario**: Assigning applicants to job openings based on skill fit    \n",
    "**Matching Table**:\n",
    "```\n",
    "Applicants  Jobs       Fit Score\n",
    "  Amy ───── Data Sci ─── 0.9\n",
    "  Sam ──┬── Engineer ── 0.7\n",
    "        └── Analyst ── 0.8\n",
    "  Zoe ───── Engineer ── 0.6\n",
    "```\n",
    "**Maximum Matching**: Amy-Data Sci (0.9), Sam-Analyst (0.8), Zoe-Engineer (0.6) → Total=2.3  \n",
    "**Resource**: [LinkedIn Matching Algorithm](https://engineering.linkedin.com/blog/2016/06/how-linkedin-uses-machine-learning-to-match-job-seekers-with-jo)\n",
    "\n",
    "---\n",
    "\n",
    "### Comparative Summary Table\n",
    "\n",
    "| Application          | Cluster Validation Analogy          | Key Metric               | Common Algorithm        |\n",
    "|----------------------|-------------------------------------|--------------------------|-------------------------|\n",
    "| Stable Marriage      | Cluster-to-class 1:1 mapping        | Preference satisfaction  | Gale-Shapley            |\n",
    "| Roommate Assignment  | Intra-cluster homogeneity           | Compatibility score      | Hungarian Algorithm     |\n",
    "| Advisor Matching     | Aligning clusters with true labels  | Research overlap         | Deferred Acceptance     |\n",
    "| Image Matching       | Cross-cluster correspondence        | Feature distance         | RANSAC                  |\n",
    "| Job Applicant        | Purity maximization                 | Skill fit percentage     | Linear Sum Assignment   |\n",
    "\n",
    "These examples demonstrate how maximum matching principles apply across domains while maintaining the core idea of optimal constrained assignments - exactly what we do when evaluating clustering quality against ground truth."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
